import streamlit as st
import pandas as pd
import numpy as np
import shap
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier, IsolationForest
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import joblib

# Streamlit session state'i baÅŸlat
if 'stage' not in st.session_state:
    st.session_state.stage = 'upload_train'
if 'model' not in st.session_state:
    st.session_state.model = None
if 'X_train' not in st.session_state:
    st.session_state.X_train = None
if 'y_train' not in st.session_state:
    st.session_state.y_train = None
if 'le' not in st.session_state: # Label Encoder (Target iÃ§in)
    st.session_state.le = None
if 'feature_names' not in st.session_state:
    st.session_state.feature_names = None
if 'model_type' not in st.session_state:
    st.session_state.model_type = None


# --- Sabitler ve YardÄ±mcÄ± Fonksiyonlar ---

MODEL_OPTIONS = {
    "Supervised (SÄ±nÄ±flandÄ±rma)": {
        "Random Forest SÄ±nÄ±flandÄ±rÄ±cÄ±": RandomForestClassifier,
        "Gradient Boosting SÄ±nÄ±flandÄ±rÄ±cÄ±": None
    },
    "Unsupervised (Anomali Tespiti)": {
        "Isolation Forest": IsolationForest,
        "One-Class SVM": None
    }
}

@st.cache_data
def handle_uploaded_data(uploaded_file, skip_target=False):
    """YÃ¼klenen CSV dosyasÄ±nÄ± okur ve temel veri temizliÄŸini yapar."""
    try:
        # Yorum satÄ±rlarÄ±nÄ± (# ile baÅŸlayanlarÄ±) atlayarak oku
        df = pd.read_csv(uploaded_file, comment='#')
        
        # Sadece sayÄ±sal ve kategorik veri tÃ¼rlerini tut, NaN olanlarÄ± ortalama ile doldur (basit yaklaÅŸÄ±m)
        for col in df.columns:
            if df[col].dtype == 'object':
                # EÄŸer target sÃ¼tunu deÄŸilse ve skip_target True ise, bu sÃ¼tunu atla
                if skip_target and col == st.session_state.target_column:
                    continue
                # Kategorik sÃ¼tunlarÄ± One-Hot Encoding iÃ§in bÄ±rak
                continue
            
            # SayÄ±sal sÃ¼tunlardaki eksik deÄŸerleri (NaN) ortalama ile doldur
            if df[col].isnull().any():
                df[col] = df[col].fillna(df[col].mean())
        
        return df
    except Exception as e:
        st.error(f"Veri yÃ¼klenirken hata oluÅŸtu: {e}")
        return None

def preprocess_data_and_train(df, model_class, target_column=None):
    """Veriyi Ã¶n iÅŸler ve modeli eÄŸitir."""
    
    # Kategori: One-Hot Encoding
    X = pd.get_dummies(df.drop(columns=[target_column]) if target_column else df, drop_first=True)
    
    if target_column: # Supervised (GÃ¶zetimli)
        y = df[target_column]
        
        # Etiket (Target) sÃ¼tununu sayÄ±sal hale getir (Label Encoding)
        le = LabelEncoder()
        y_encoded = le.fit_transform(y)
        st.session_state.le = le
        st.session_state.feature_names = X.columns.tolist()

        # Modeli EÄŸit
        X_train, _, y_train, _ = train_test_split(X, y_encoded, test_size=0.2, random_state=42)
        model = model_class(random_state=42, n_estimators=100)
        model.fit(X_train, y_train)
        
        # EÄŸitim verilerini session state'e kaydet (SHAP iÃ§in gerekli)
        st.session_state.X_train = X_train
        st.session_state.y_train = y_train
        
        return model, X_train.columns.tolist()
    
    else: # Unsupervised (GÃ¶zetimsiz)
        
        # Modeli EÄŸit (tÃ¼m veri ile)
        model = model_class(random_state=42)
        model.fit(X)
        
        st.session_state.X_train = X # SHAP iÃ§in tÃ¼m X verisini kullan
        st.session_state.feature_names = X.columns.tolist()
        
        return model, X.columns.tolist()


def plot_shap_waterfall(explainer, shap_values, input_df, class_index, title, prediction_label):
    """Tek bir Ã¶rnek iÃ§in SHAP Waterfall grafiÄŸi Ã§izer."""
    
    # SHAP Explanation objesi iÃ§in deÄŸerleri ve beklenen deÄŸeri al
    if isinstance(shap_values, list):
        # SÄ±nÄ±flandÄ±rma modelleri iÃ§in: Sadece tahmin edilen sÄ±nÄ±fa ait SHAP deÄŸerlerini kullan
        shap_values_to_plot = shap_values[class_index][0]
        base_value = explainer.expected_value[class_index]
    else:
        # Anomali modelleri iÃ§in: Tek bir Ã§Ä±ktÄ± vektÃ¶rÃ¼ vardÄ±r
        shap_values_to_plot = shap_values[0]
        base_value = explainer.expected_value
        
    explanation = shap.Explanation(
        values=shap_values_to_plot,
        base_values=base_value,
        data=input_df.iloc[0].values,
        feature_names=input_df.columns.tolist()
    )
    
    # Waterfall plot Ã§izimi
    fig, ax = plt.subplots(figsize=(10, 6))
    shap.plots.waterfall(explanation, show=False)
    ax.set_title(f"'{prediction_label}' Tahminine KatkÄ±lar", fontsize=14)
    st.pyplot(fig)
    plt.close(fig)

# --- UI YapÄ±sÄ± ---

st.title("ğŸ’¡ Model Reveal: XAI Karar MekanizmasÄ± Analizi")
st.markdown("Ä°nteraktif bir Streamlit uygulamasÄ±yla ML modelinizin neden o Ã§Ä±ktÄ±yÄ± verdiÄŸini keÅŸfedin.")

# --- Sol Panel (Ayarlar ve AÅŸamalar) ---

st.sidebar.header("Uygulama AkÄ±ÅŸÄ±")
st.sidebar.markdown(f"**GÃ¼ncel AÅŸama:** `{st.session_state.stage}`")
st.sidebar.markdown("---")


# ===============================================
# AÅAMA 1: EÄÄ°TÄ°M VERÄ°SÄ° YÃœKLE
# ===============================================
if st.session_state.stage == 'upload_train':
    st.header("1. EÄŸitim Verisini YÃ¼kleyin (.csv)")
    uploaded_train_file = st.file_uploader(
        "LÃ¼tfen modelinizi eÄŸitmek iÃ§in .csv dosyanÄ±zÄ± yÃ¼kleyin (Ä°lk 15 satÄ±rlÄ±k Kredi Riski verisini kullanabilirsiniz).", 
        type="csv"
    )
    
    if uploaded_train_file is not None:
        train_df = handle_uploaded_data(uploaded_train_file)
        if train_df is not None:
            st.session_state.train_df = train_df
            st.success("EÄŸitim verisi baÅŸarÄ±yla yÃ¼klendi!")
            st.dataframe(train_df.head(), use_container_width=True)
            st.session_state.stage = 'select_model'
            st.rerun() # Yeni aÅŸamaya geÃ§

# ===============================================
# AÅAMA 2: MODEL SEÃ‡Ä°MÄ° VE EÄÄ°TÄ°M
# ===============================================
if st.session_state.stage == 'select_model':
    st.header("2. Model SeÃ§imi ve EÄŸitimi")
    
    # Model TÃ¼rÃ¼ SeÃ§imi
    model_category = st.selectbox(
        "Model Kategorisi",
        list(MODEL_OPTIONS.keys())
    )
    
    # Model SÄ±nÄ±fÄ± SeÃ§imi
    model_name = st.selectbox(
        "Model SÄ±nÄ±fÄ±",
        list(MODEL_OPTIONS[model_category].keys()),
        disabled=(MODEL_OPTIONS[model_category].get(list(MODEL_OPTIONS[model_category].keys())[0]) is None) # EÄŸer model None ise pasif yap
    )
    
    st.session_state.model_type = model_category
    st.session_state.model_class = MODEL_OPTIONS[model_category][model_name]
    
    if model_category == "Supervised (SÄ±nÄ±flandÄ±rma)":
        
        # Etiket (Target) SÃ¼tunu SeÃ§imi
        target_column = st.selectbox(
            "Etiket (Target) SÃ¼tununu SeÃ§in",
            st.session_state.train_df.columns
        )
        st.session_state.target_column = target_column

        # Etiket kontrolÃ¼
        if st.session_state.train_df[target_column].dtype not in ['int64', 'float64']:
            st.info(f"SeÃ§ilen '{target_column}' sÃ¼tunu metin iÃ§eriyor. Model eÄŸitimi Ã¶ncesinde Label Encoding uygulanacaktÄ±r.")
        
        # Ã–zellikler kontrolÃ¼ (Etiket hariÃ§ hepsi sayÄ±sal/kategorik olmalÄ±)
        feature_cols = st.session_state.train_df.drop(columns=[target_column]).columns
        
        st.info("Supervised model seÃ§tiniz. Veri setinizde bir etiket (target) sÃ¼tunu olmalÄ±dÄ±r. Model eÄŸitimi, kategori dÃ¶nÃ¼ÅŸÃ¼mÃ¼ (One-Hot Encoding) yapÄ±larak gerÃ§ekleÅŸtirilecektir.")
        
    else:
        st.info("Unsupervised model seÃ§tiniz. Veri setinizde etiket (target) sÃ¼tunu gerekli deÄŸildir. Model (Isolation Forest), verideki aykÄ±rÄ± noktalarÄ± tespit etmek iÃ§in eÄŸitilecektir.")

    if st.button(f"'{model_name}' Modelini EÄŸit", type="primary"):
        with st.spinner("Model eÄŸitiliyor ve veri Ã¶niÅŸleniyor..."):
            try:
                # Veri Ã¶niÅŸleme ve eÄŸitim
                st.session_state.model, feature_names = preprocess_data_and_train(
                    st.session_state.train_df, 
                    st.session_state.model_class, 
                    st.session_state.target_column if model_category == "Supervised (SÄ±nÄ±flandÄ±rma)" else None
                )
                st.success(f"{model_name} baÅŸarÄ±yla eÄŸitildi!")
                st.session_state.feature_names = feature_names
                st.session_state.stage = 'upload_test'
                st.rerun()
            except Exception as e:
                st.error(f"Model eÄŸitimi sÄ±rasÄ±nda hata oluÅŸtu: {e}. LÃ¼tfen veri tiplerini kontrol edin.")

# ===============================================
# AÅAMA 3: TEST VERÄ°SÄ° YÃœKLEME VE TAHMÄ°N
# ===============================================
if st.session_state.stage == 'upload_test':
    st.header("3. Test Verisini YÃ¼kleyin (.csv)")
    st.info(f"EÄŸitilen model: **{st.session_state.model_type}** | YÃ¼kleyeceÄŸiniz veri, eÄŸitim verisindeki sÃ¼tunlarla ({len(st.session_state.feature_names)} Ã¶zellik) uyumlu olmalÄ±dÄ±r.")
    
    uploaded_test_file = st.file_uploader(
        "Tahmin ve XAI analizi iÃ§in tek bir Ã¶rnek iÃ§eren test .csv dosyanÄ±zÄ± yÃ¼kleyin (Risk sÃ¼tunu olmamalÄ±dÄ±r).", 
        type="csv"
    )
    
    if uploaded_test_file is not None:
        test_df = handle_uploaded_data(uploaded_test_file, skip_target=True)
        if test_df is not None:
            
            # Test verisine eÄŸitim verisine uygulanan dÃ¶nÃ¼ÅŸÃ¼mleri uygula (One-Hot Encoding)
            test_X_raw = test_df.copy()
            test_X_processed = pd.get_dummies(test_X_raw, drop_first=True).reindex(columns=st.session_state.feature_names, fill_value=0)
            
            if test_X_processed.shape[0] != 1:
                st.warning("Test verisi sadece tek bir Ã¶rnek (tek bir satÄ±r) iÃ§ermelidir.")
            else:
                st.session_state.test_X = test_X_processed
                st.session_state.test_X_raw = test_X_raw # SHAP'ta daha anlaÅŸÄ±lÄ±r isimler iÃ§in
                st.session_state.stage = 'reveal_result'
                st.rerun()

# ===============================================
# AÅAMA 4: SONUÃ‡ VE XAI ANALÄ°ZÄ°
# ===============================================
if st.session_state.stage == 'reveal_result':
    st.header("4. Model Reveal: SonuÃ§ ve Nedenleri")
    
    test_X_processed = st.session_state.test_X
    test_X_raw = st.session_state.test_X_raw
    model = st.session_state.model
    
    # 1. Tahmin Yap
    if st.session_state.model_type == "Supervised (SÄ±nÄ±flandÄ±rma)":
        # SÄ±nÄ±flandÄ±rma Tahmini
        prediction_value = model.predict(test_X_processed)[0]
        prediction_label = st.session_state.le.inverse_transform([prediction_value])[0] # Orijinal etikete geri Ã§evir
        
        proba = model.predict_proba(test_X_processed)[0]
        confidence = max(proba) * 100
        
        # Tahmin ve Nedenleri Yan Yana GÃ¶ster
        col_tahmin, col_shap = st.columns([1, 2])
        
        with col_tahmin:
            st.subheader("ğŸ¯ Tahmin Sonucu")
            st.success(f"SÄ±nÄ±f: **{prediction_label}**")
            st.metric(label="GÃ¼venirlik", value=f"{confidence:.2f}%")
            
            st.markdown("---")
            st.subheader("Girdi DeÄŸerleri")
            st.dataframe(test_X_raw.T, use_container_width=True)


        with col_shap:
            st.subheader("ğŸ“Š SHAP AÃ§Ä±klamasÄ± (Neden?)")
            
            # SHAP Explainer oluÅŸtur ve hesapla
            explainer = shap.TreeExplainer(model)
            shap_values = explainer.shap_values(test_X_processed)
            
            # SHAP'Ä± sadece tahmin edilen sÄ±nÄ±f iÃ§in gÃ¶rselleÅŸtir
            plot_shap_waterfall(
                explainer, 
                shap_values, 
                test_X_processed, # OHE'li veriyi kullan
                prediction_value, 
                f"'{prediction_label}' Tahminine KatkÄ±lar",
                prediction_label
            )
            st.caption("Grafik, tahminin temel ortalama Ã§Ä±ktÄ±dan nasÄ±l saptÄ±ÄŸÄ±nÄ± ve hangi Ã¶zelliklerin (OHE'li) bu sapmaya ne kadar katkÄ± saÄŸladÄ±ÄŸÄ±nÄ± gÃ¶sterir.")

    else: # Unsupervised (Anomali Tespiti)
        # Anomali Tespiti Tahmini
        prediction_value = model.predict(test_X_processed)[0] # -1 veya 1
        prediction_label = "Anomali (AykÄ±rÄ± DeÄŸer)" if prediction_value == -1 else "Normal"
        
        # Anomali skorunu al (daha dÃ¼ÅŸÃ¼k skor = daha yÃ¼ksek anomali)
        anomaly_score = model.decision_function(test_X_processed)[0]
        
        col_tahmin, col_shap = st.columns([1, 2])

        with col_tahmin:
            st.subheader("ğŸ¯ Tespit Sonucu")
            if prediction_value == -1:
                st.error(f"Tespit: **{prediction_label}**")
            else:
                st.success(f"Tespit: **{prediction_label}**")
            st.metric(label="Anomali Skoru", value=f"{anomaly_score:.4f}", delta=f"{'Daha DÃ¼ÅŸÃ¼k = Daha Anormal' if anomaly_score < 0 else 'Daha YÃ¼ksek = Daha Normal'}")
            
            st.markdown("---")
            st.subheader("Girdi DeÄŸerleri")
            st.dataframe(test_X_raw.T, use_container_width=True)


        with col_shap:
            st.subheader("ğŸ“Š SHAP AÃ§Ä±klamasÄ± (Neden?)")

            # SHAP Explainer oluÅŸtur ve hesapla
            explainer = shap.TreeExplainer(model)
            # Isolation Forest genellikle sadece tek bir Ã§Ä±ktÄ± deÄŸeri dÃ¶ndÃ¼rÃ¼r.
            shap_values = explainer.shap_values(test_X_processed) 
            
            plot_shap_waterfall(
                explainer, 
                np.array([shap_values]), # SHAP'a tek bir deÄŸer gibi sunmak iÃ§in
                test_X_processed, 
                0, # Index Ã¶nemsiz
                f"'{prediction_label}' KararÄ±na KatkÄ±lar",
                prediction_label
            )
            st.caption("Grafik, Ã¶rneÄŸin neden anormal (negatif sapma) veya normal (pozitif sapma) olarak sÄ±nÄ±flandÄ±rÄ±ldÄ±ÄŸÄ±na dair Ã¶zellik katkÄ±larÄ±nÄ± gÃ¶sterir.")

    if st.button('Yeni Analiz BaÅŸlat', type="secondary"):
        st.session_state.stage = 'upload_train'
        st.session_state.model = None
        st.session_state.test_X = None
        st.session_state.le = None
        st.rerun()
